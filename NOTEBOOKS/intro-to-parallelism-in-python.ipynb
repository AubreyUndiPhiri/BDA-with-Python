{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f78faaea",
   "metadata": {},
   "source": [
    "# Parallel Processing in Python\n",
    "In this tutorial, you will learn how to use the Python builtin Multiprocessing library to parallelize computations. This is often one of the first  step when dealing large computations. We will cover the following:\n",
    "- Using Multiprocessing with a single parameter function\n",
    "- Using Multiprocessing with multiple parameters function\n",
    "- Use joblib library for paralellizing functions\n",
    "- Other ways to parallelize functions in Python\n",
    "\n",
    "For more technical details about the multiprocessing library, please see the documentation [here](https://docs.python.org/3/library/multiprocessing.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe2c0e1",
   "metadata": {},
   "source": [
    "# Python setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a0f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import asyncio\n",
    "import time\n",
    "import aiohttp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc04c1e",
   "metadata": {},
   "source": [
    "# Optimizing Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243e7e36",
   "metadata": {},
   "source": [
    "## Read only a subset of the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf46cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_40gb = \"/Volumes/GoogleDrive/My Drive/WBG/Mozambique/data-cdrs/mCellCDRs.csv\"\n",
    "# df_first_5mill = pd.read_csv(file_40gb, nrows=5000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9c7ca3",
   "metadata": {},
   "source": [
    "## Read data in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d851161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set chunck size to 5 million rows\n",
    "chunksize = 2*1e6\n",
    "cnt = 1\n",
    "tot_rows = 0\n",
    "with pd.read_csv(file_40gb, chunksize=chunksize) as reader:\n",
    "    for chunk in reader:\n",
    "        print(\"Working on chunk: {}\".format(cnt))\n",
    "        print(chunk.shape)\n",
    "        tot_rows += chunk.shape[0]\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410e040f",
   "metadata": {},
   "source": [
    "## Read only a subset of columns\n",
    "With pandas, you can also read a subset of the columns instead reading all columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24245b8f",
   "metadata": {},
   "source": [
    "### EXERCISE-1: Which arguement do you use to read only a subset of columns in pandas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b3d5fc",
   "metadata": {},
   "source": [
    "# Speeding up IO Bound Programs\n",
    "Refer to the Python script for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f13db9c",
   "metadata": {},
   "source": [
    "## Using multiprocessing with a single parameter function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a77a501",
   "metadata": {},
   "source": [
    "## Define function we would like to run\n",
    "For the sake demonstration here, we will define a very simple function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530951f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(num):\n",
    "    return num**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09224682",
   "metadata": {},
   "source": [
    "## Run the function sequentially on a big list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f8eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [square(x) for x in list(range(100000))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d673c",
   "metadata": {},
   "source": [
    "## Run with multiprocessing\n",
    "These lines create a multiprocessing pool of eight workers, and we can use this pool to map our required function to this list. The Pool class represents a pool of worker processes. It has methods which allows tasks to be offloaded to the worker processes in a few different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d48e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(8)\n",
    "result = pool.map(square,list(range(100000)))\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba8f987",
   "metadata": {},
   "source": [
    "## Compare the linear/sequential processing with the parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6acd7c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def run_func(list_length):\n",
    "    print(\"Size of List:{}\".format(list_length))\n",
    "    t0 = time.time()\n",
    "    result1 = [square(x) for x in list(range(list_length))]\n",
    "    t1 = time.time()\n",
    "    diff = round(t1-t0, 4)\n",
    "    print(\"Running time-Sequential Processing: {} seconds\".format(diff))\n",
    "    time_without_multiprocessing = diff\n",
    "    # Run with multiprocessing\n",
    "    t0 = time.time()\n",
    "    pool = Pool(8)\n",
    "    result2 = pool.map(square,list(range(list_length)))\n",
    "    pool.close()\n",
    "    t1 = time.time()\n",
    "    diff = round(t1-t0, 4)\n",
    "    print(\"Running time-Multiprocessing: {} seconds\".format(diff))\n",
    "    time_with_multiprocessing = diff\n",
    "    return time_without_multiprocessing, time_with_multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a7aed",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    times_taken = []\n",
    "    for i in range(1, 9):\n",
    "        list_length = 10**i\n",
    "        time_seq, time_parallel = run_func(list_length)\n",
    "        times_taken.append([list_length, 'No Multiproc', time_seq])\n",
    "        times_taken.append([list_length, 'Multiproc', time_parallel])\n",
    "\n",
    "    timedf = pd.DataFrame(times_taken,columns = ['list_length', 'type','time_taken'])\n",
    "    fig =  px.line(timedf,x = 'List-Length',y='Timetaken',color='type',log_x=True)\n",
    "    plotly.offline.plot(fig, filename='comparison_bw_multiproc.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b034d",
   "metadata": {},
   "source": [
    "### EXERCISE-2: \n",
    "1. Make the function 3 seconds slower and report what happens. **Hint.** You can use ```time.sleep(seconds)``` to simulate a more tie consumning function.\n",
    "2. Find out the number of logical processors on your machine\n",
    "3. Reduce the number of processors available to Pool and see if it has effect on the running time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c28c706",
   "metadata": {},
   "source": [
    "## Using multiprocessing with multiple parameter function\n",
    "We can extend the code above to run a function with multiple parameters. We can simply use the ```starmap``` method for ```Pool``` to achieve this as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888aa275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_add(num1, num2):\n",
    "    return num1**2 + num2**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6939d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processors = Pool(4)\n",
    "params = [[100,4],[150,5],[200,6],[300,4]]\n",
    "results = processors.starmap(square_add, params)\n",
    "processors.close()\n",
    "print(results[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6842ae69",
   "metadata": {},
   "source": [
    "# Other ways to utilize multiprocessing in Python\n",
    "There are other libraries which can be used to achieve parallization in Python. FOr example:\n",
    "1. [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html). Although its also a builtin library, it is considered more high level and relatively easier to use than using multiprocessing directly.\n",
    "2. [Joblib](https://joblib.readthedocs.io/en/latest/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
